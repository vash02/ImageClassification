{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('/gdrive/MyDrive/AML_FashionDataset/topwear')))\n",
    "print(len(os.listdir('/gdrive/MyDrive/AML_FashionDataset/bottomwear')))\n",
    "print(len(os.listdir('/gdrive/MyDrive/AML_FashionDataset/footwear')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Resizing images and converting to grayscale (Part 3 preprocessing)\n",
    "<br>\n",
    "def load_and_preprocess_images(*folder_path):<br>\n",
    "    image_files = []<br>\n",
    "    images = []<br>\n",
    "    labels = []<br>\n",
    "    for fp in folder_path:<br>\n",
    "      image_files = sorted(os.listdir(fp))<br>\n",
    "      for filename in image_files:<br>\n",
    "        img = Image.open(os.path.join(fp, filename))<br>\n",
    "        img = img.convert('L')<br>\n",
    "        img = img.resize((224,224))<br>\n",
    "        img_array = np.array(img)<br>\n",
    "        images.append(img_array)<br>\n",
    "        if 'topwear' in filename:<br>\n",
    "          label = 1<br>\n",
    "        if 'bottomwear' in filename:<br>\n",
    "          label = 2<br>\n",
    "        if 'footwear' in filename:<br>\n",
    "          label = 3<br>\n",
    "        labels.append(label)<br>\n",
    "    return images, labels<br>\n",
    "import os<br>\n",
    "import numpy as np<br>\n",
    "import tensorflow as tf<br>\n",
    "from keras import layers, models<br>\n",
    "from sklearn.model_selection import train_test_split<br>\n",
    "from sklearn.preprocessing import LabelEncoder<br>\n",
    "from sklearn.metrics import accuracy_score<br>\n",
    "from scipy.spatial import procrustes<br>\n",
    "import os<br>\n",
    "import numpy as np<br>\n",
    "import matplotlib.pyplot as plt<br>\n",
    "from sklearn.decomposition import PCA<br>\n",
    "from PIL import Image<br>\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator<br>\n",
    "from tensorflow.keras.models import Sequential<br>\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, ZeroPadding2D<br>\n",
    "from tensorflow.keras.optimizers import Adam<br>\n",
    "from tensorflow.keras import callbacks<br>\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler<br>\n",
    "import time<br>\n",
    "np.random.seed(42)<br>\n",
    "tf.random.set_seed(42)<br>\n",
    "images, labels = load_and_preprocess_images('/gdrive/MyDrive/AML_FashionDataset/topwear/',<br>\n",
    "                                            '/gdrive/MyDrive/AML_FashionDataset/bottomwear/',<br>\n",
    "                                            '/gdrive/MyDrive/AML_FashionDataset/footwear/')<br>\n",
    "all_images = np.array(images)<br>\n",
    "all_labels = np.array(labels)<br>\n",
    "all_labels = np.array(pd.get_dummies(all_labels))<br>\n",
    " Part 2: Split the images into a training set, a validation set, and a test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(all_images, all_labels, random_state=42)  # shuffle to ensure that the images of each class occur one after the other in a random order rather than class 0 being followed by class 1 and then class 2\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) # stratify to ensure that equal proportions of each class are present in each set\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, stratify=y_test_val, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab_list = []\n",
    "for i in y_train:\n",
    "  train_lab_list.append(list(i).index(1))\n",
    "print(Counter(train_lab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lab_list = []\n",
    "for i in y_val:\n",
    "  val_lab_list.append(list(i).index(1))\n",
    "print(Counter(val_lab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lab_list = []\n",
    "for i in y_test:\n",
    "  test_lab_list.append(list(i).index(1))\n",
    "print(Counter(test_lab_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 3: Build the input pipeline, including the appropriate preprocessing operations, and add data augmentation.\n",
    "<br>\n",
    "image_size = 224<br>\n",
    "X_train = X_train.reshape(-1, image_size, image_size, 1)<br>\n",
    "X_val = X_val.reshape(-1, image_size, image_size, 1)<br>\n",
    "X_test = X_test.reshape(-1, image_size, image_size, 1)<br>\n",
    "# y_train = np.array(pd.get_dummies(y_train))<br>\n",
    "# y_val = np.array(pd.get_dummies(y_val))<br>\n",
    "# y_test = np.array(pd.get_dummies(y_test))<br>\n",
    "datagen_train = ImageDataGenerator(<br>\n",
    "    rotation_range=180,<br>\n",
    "    zoom_range=0.2,<br>\n",
    "    width_shift_range=0.2,<br>\n",
    "    height_shift_range=0.2,<br>\n",
    "    horizontal_flip=True,<br>\n",
    "    vertical_flip=True  # Allowing vertical flip as well<br>\n",
    ")<br>\n",
    " Part 4: Fine-tune a pretrained model of your choice on this dataset (the one you created in part 3). Report classification accuracy and give a few examples of correct/incorrect classification (show a few images that were correctly/incorrectly classified).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "image_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['topwear','bottomwear','footwear']\n",
    "for category in categories:\n",
    "    category_dir = os.path.join('/gdrive/MyDrive/AML_FashionDataset/', category)\n",
    "\n",
    "    # Get a list of all image files in the category\n",
    "    category_images = [os.path.join(category_dir, img) for img in os.listdir(category_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Add image paths to the list\n",
    "    image_paths.extend(category_images)\n",
    "\n",
    "    # Add labels (category) to the list\n",
    "    image_labels.extend([category] * len(category_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train_test_split to split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, image_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further split the training set into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2 (20% for validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the number of samples in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of validation samples:\", len(X_val))\n",
    "print(\"Number of testing samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have a DataFrame df with 'image_path' and 'label' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'image_path': X_train, 'label': y_train})\n",
    "df_val = pd.DataFrame({'image_path': X_val, 'label': y_val})\n",
    "df_test = pd.DataFrame({'image_path': X_test, 'label': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image size and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=df_val,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Set to False to maintain the order\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rying with ResNet50 & then InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    " tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the base model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_model in base_models:\n",
    "  print(f\"Training with {base_model} pretrained layers\")\n",
    "  for layer in base_model.layers:\n",
    "      layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Create your custom classification head\n",
    "  num_classes = len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  model = models.Sequential([\n",
    "      base_model,\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dropout(0.5),\n",
    "      layers.Dense(num_classes, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Compile the model\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Train the model\n",
    "  epochs = 10  # Adjust the number of epochs as needed\n",
    "  model.fit(\n",
    "      train_generator,\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Evaluate the model\n",
    "  test_loss, test_acc = model.evaluate(test_generator)\n",
    "  print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  if test_acc < 1:\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(test_generator)\n",
    "\n",
    "    # Get the predicted labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get the true labels\n",
    "    true_labels = test_generator.classes\n",
    "\n",
    "    # Find indices of incorrect and correct predictions\n",
    "    incorrect_indices = np.where(predicted_labels != true_labels)[0]\n",
    "    correct_indices = np.where(predicted_labels == true_labels)[0]\n",
    "\n",
    "    # Extract corresponding image paths for reporting\n",
    "    incorrect_image_paths = df_test.iloc[incorrect_indices]['image_path'].tolist()\n",
    "    correct_image_paths = df_test.iloc[correct_indices]['image_path'].tolist()\n",
    "\n",
    "    # Report incorrect and correct classified examples\n",
    "    print(\"Incorrectly Classified Examples:\")\n",
    "    for image_path in incorrect_image_paths:\n",
    "        print(image_path)\n",
    "    print(\"\\nCorrectly Classified Examples:\")\n",
    "    for image_path in correct_image_paths:\n",
    "        print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Fine Tuning:<br>\n",
    "###First Pre-trained Layer Model - ResNet50<br>\n",
    "1. Training accuracy reaches 67.22% after 10 epochs.<br>\n",
    "2. Test accuracy is 68.85%, which doesn't seems like great accuracy given we are using pre-trained model.<br>\n",
    "3. We oberved val accuracy of 52.46% which implies the ResNet with frozen layers is underfitting, so we tried making the model a little more complex with increasing the number of neurons in additional dense layers from 128 to 256 and 512, but the accuracy still didn't go up significantly.<br>\n",
    "4. We tried early stopping and reducing LR on plateau techniques along with Adam optimizer and dropout layer for fine tuning and optimization but still the accuracy went upto max 82% with a random split of train, validation and test set case.<br>\n",
    "5. Then, based on results we tried to use different set of pretrained layer model i.e. Google's InceptionV3<br>\n",
    "###Second Pre-trained Layer Model - InceptionV3<br>\n",
    "1. The model achieves strong performance on both the training and validation sets.<br>\n",
    "2. The test accuracy is also high at 95.08%, suggesting good generalization to unseen data.<br>\n",
    "3. The training process seems stable with consistent improvement in both loss and accuracy over epochs.<br>\n",
    "4. For both the models we used preprocess_input from vgg16 pretrained model, the preprocess input from vgg16 combined with InceptionV3 model gave good results (95% accuracy), with frozen layers and GlobalAveragePoolingLayer, Dense layer on top with 128 neurons and 0.5 dropout along with Adam optimizer whileÂ compiltation.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
